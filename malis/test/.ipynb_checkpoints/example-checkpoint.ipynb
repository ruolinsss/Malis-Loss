{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/haicu/ruolin.shen/anaconda3/envs/malis_tensor/lib/python3.7/site-packages/malis\n"
     ]
    }
   ],
   "source": [
    "### use keras with backend tensorflow as a test example\n",
    "### tensorflow version 2.1.0\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D,Lambda,Activation,concatenate\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "from malis.malis_utils import mknhood3d,seg_to_affgraph,malis_weights,affgraph_to_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Loading test data (can be downloaded on https://cremi.org/data/)\n",
    "f = h5py.File('./test_data/sample_A_20160501.hdf','r')\n",
    "raw_data = f['volumes']['raw']\n",
    "seg_gt = f['volumes']['labels']['neuron_ids']\n",
    "\n",
    "##### Data preprocessing, affinity ground truth should be prepared\n",
    "nhood = mknhood3d(1)\n",
    "e = nhood.shape[0]\n",
    "aff_gt = seg_to_affgraph(seg_gt, nhood)   #The seg_gt needs to be reshaped as (z,y,x) and the output aff_gt has shape of (edge,z,y,x) \n",
    "\n",
    "# adding dimensions to have 5d input data (batch,channel,x,y,z)\n",
    "data_ch = np.expand_dims(np.expand_dims(data,axis=0),axis=1)   #(batch,channel=1,z,y,x)\n",
    "aff_gt_label = np.expand_dims(aff_gt_label,axis=0)             #(batch,channel=edge,z,y,x)\n",
    "seg_gt = np.expand_dims(np.expand_dims(seg_gt,axis=0),axis=1)  #(batch,channel=1, z,y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Loss example for keras (tensorflow backend)\n",
    "def MALIS_loss(seg_gt):\n",
    "    \n",
    "    def loss(y_true,y_pred):\n",
    "        \n",
    "        z = K.int_shape(y_pred)[2]\n",
    "        y = K.int_shape(y_pred)[3]\n",
    "        x = K.int_shape(y_pred)[4]\n",
    "\n",
    "        new_y_true = K.reshape(y_true,(e,-1,y,x))\n",
    "        new_y_pred = K.reshape(y_pred,(e,-1,y,x))\n",
    "        new_seg = K.reshape(seg_gt,(-1,y,x))\n",
    "        \n",
    "        pos_t, neg_t = tf.py_function(\n",
    "            malis_weights,\n",
    "            [new_y_pred, new_y_true, new_seg, nhood],\n",
    "            [tf.int32,tf.int32])\n",
    "        pos_t = tf.cast(pos_t,tf.float32)\n",
    "        neg_t = tf.cast(neg_t,tf.float32)\n",
    "        \n",
    "        loss = tf.reduce_sum(pos_t * new_y_pred)\n",
    "        \n",
    "        return loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 124, 124, 124)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 32, 124, 124, 124) 896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 124, 124, 124) 0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 32, 62, 62, 62)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 64, 62, 62, 62)    55360     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 62, 62, 62)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 64, 31, 31, 31)    0         \n",
      "_________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3 (None, 64, 62, 62, 62)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 64, 62, 62, 62)    110656    \n",
      "_________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3 (None, 64, 124, 124, 124) 0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 32, 124, 124, 124) 55328     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 4, 124, 124, 124)  132       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 124, 124, 124)  0         \n",
      "=================================================================\n",
      "Total params: 222,372\n",
      "Trainable params: 222,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "13/13 [==============================] - 569s 44s/step - loss: 44759945216.0000 - val_loss: 4445628928.0000\n",
      "Epoch 2/3\n",
      "13/13 [==============================] - 590s 45s/step - loss: 2418687233.2308 - val_loss: 4445625344.0000\n",
      "Epoch 3/3\n",
      "13/13 [==============================] - 577s 44s/step - loss: 4001235904.6154 - val_loss: 4445622784.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fea4217e310>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### A very simple network example\n",
    "inputShape = (data_ch.shape[1], data_ch.shape[2], data_ch.shape[3], data_ch.shape[4])\n",
    "\n",
    "inputs = Input(shape=(inputShape))\n",
    "input_seg = Input(shape=(inputShape))\n",
    "conv_block_1 = Conv3D(32, (3, 3, 3), strides=(1, 1, 1), padding='same')(inputs)\n",
    "conv_block_1 = Activation('relu')(conv_block_1)\n",
    "pool_block_1 = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2))(conv_block_1)\n",
    "\n",
    "conv_block_2 = Conv3D(64, (3, 3, 3), strides=(1, 1, 1), padding='same')(pool_block_1)\n",
    "conv_block_2 = Activation('relu')(conv_block_2)\n",
    "pool_block_2 = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2))(conv_block_2)\n",
    "\n",
    "\n",
    "up_block_1 = UpSampling3D((2, 2, 2))(pool_block_2)\n",
    "up_block_1 = Conv3D(64, (3, 3, 3), strides=(1, 1, 1), padding='same')(up_block_1)\n",
    "up_block_2 = UpSampling3D((2, 2, 2))(up_block_1)\n",
    "up_block_2 = Conv3D(32, (3, 3, 3), strides=(1, 1, 1), padding='same')(up_block_2)\n",
    "conv_block_10 = Conv3D(e, (1, 1, 1), strides=(1, 1, 1), padding='same')(up_block_2) #### output of the network is affinity graph\n",
    "outputs = Activation('sigmoid')(conv_block_10)\n",
    "\n",
    "##### raw data, segmentation label and affinity label should be input to the network\n",
    "model = Model(inputs=[inputs,input_seg], outputs=outputs)\n",
    "model.compile(optimizer='adadelta', loss=MALIS_loss(input_seg))\n",
    "model.summary()\n",
    "model.fit([data_ch,seg_gt],aff_gt_label,epochs=3,verbose=1,batch_size=1,validation_split = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Data postprocessing: get segmentation image from affinity graph\n",
    "seg_pred = affgraph_to_seg(aff_pred,nhood,size_thresh=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python malis_tensor",
   "language": "python",
   "name": "malis_tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
